{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EGaraldi/EPIC_5/blob/main/Tutorials/tutorial_5/cosmo_sim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c0f9a13",
      "metadata": {
        "id": "1c0f9a13"
      },
      "source": [
        "Analyzing cosmological simulations\n",
        "=================================="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ca9be24",
      "metadata": {
        "id": "8ca9be24"
      },
      "source": [
        "# Step 0: getting the data\n",
        "In a bit, we will use the data from the TNG100-3 simulation. Since they are a bit large, better start the download now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6249e154",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6249e154",
        "outputId": "d76d3450-45fd-4c25-8104-9f3c0ff184c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-08-04 23:50:34--  https://datashare.mpcdf.mpg.de/s/w7SqBPunS5dNSFE/download\n",
            "Resolving datashare.mpcdf.mpg.de (datashare.mpcdf.mpg.de)... 130.183.207.3\n",
            "Connecting to datashare.mpcdf.mpg.de (datashare.mpcdf.mpg.de)|130.183.207.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7935913673 (7.4G) [application/gzip]\n",
            "Saving to: ‘tng100-3.tar.gz’\n",
            "\n",
            "tng100-3.tar.gz     100%[===================>]   7.39G  25.8MB/s    in 5m 5s   \n",
            "\n",
            "2025-08-04 23:55:40 (24.8 MB/s) - ‘tng100-3.tar.gz’ saved [7935913673/7935913673]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://datashare.mpcdf.mpg.de/s/w7SqBPunS5dNSFE/download -O tng100-3.tar.gz\n",
        "!mkdir tng100-3\n",
        "!tar -xzvf tng100-3.tar.gz -C tng100-3\n",
        "!rm tng100-3.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8068080",
      "metadata": {
        "id": "a8068080"
      },
      "outputs": [],
      "source": [
        "# smaller simulation\n",
        "!wget https://datashare.mpcdf.mpg.de/s/uYAfv1BYL3ffEf4/download -O small_sim_snap013.tar.gz\n",
        "!mkdir small_sim\n",
        "!tar -xzf small_sim_snap013.tar.gz -C small_sim\n",
        "!rm small_sim_snap013.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aadba99",
      "metadata": {
        "id": "7aadba99"
      },
      "source": [
        "# What is a cosmological simulation?\n",
        "In astrophysics, numerical simulations are a fundamental tool. There are two main reasons why:\n",
        "* stars, planets, galaxies, ... are extremely complex systems, so even if we understand basic physical laws, it's impossible to predict how these interact with pen and paper\n",
        "* science is based on a cycle of observation-hypothesis-experiments, but in astrophysics we can not manipulate the Universe to make experiments. Therefore, we need to turn to virtual universes (simulations) to make virtual experiments\n",
        "\n",
        "These simulations combine different ingredients:\n",
        "* gravity\n",
        "* fluid dynamics\n",
        "* chemistry\n",
        "* (sometimes) radiation\n",
        "* (sometimes) magnetic fields\n",
        "\n",
        "Then, starting from our best guess on the conditions of the Universe after the Big Bang, we evolve these synthetic universes until today and use them to run experiments, understand observations, etc.\n",
        "\n",
        "![sim](https://thesan-project.com/thesan/images/simulations_cartoon.png)\n",
        "\n",
        "Let's start with some visualizations to get an idea of what we are dealing with. For example, the distribution of matter in one of these simulations looks like this:\n",
        "\n",
        "![cosmic_web_millenium](https://astrobites.org/wp-content/uploads/2012/07/cosmic-web.jpg)\n",
        "\n",
        "If we start to zoom in, we can see individual galaxies, for example here;\n",
        "\n",
        "![galaxy](https://github.com/EGaraldi/EPIC_5/blob/main/Tutorials/tutorial_5/tng_visual.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b14202a",
      "metadata": {
        "id": "4b14202a"
      },
      "source": [
        "# The AREPO code\n",
        "There are many different simulations codes, and each one of them works in a different way and saves the data in different formats.\n",
        "\n",
        "For this tutorial, we will work with a simulation produced with a code called AREPO. Let's familiarize with it a bit\n",
        "\n",
        "## Types of resolution elements\n",
        "\n",
        "### Fliuds (gas)\n",
        "\n",
        "AREPO uses a 3D mesh to discretize fluids. For example, the continuous fluid on the left, can be discretized using a Cartesian mesh (right) where each cell represents the fluid in it.  \n",
        "\n",
        "![mesh](https://github.com/EGaraldi/EPIC_5/blob/main/Tutorials/tutorial_5/mesh.png?raw=1)\n",
        "\n",
        "AREPO is unique because it uses a Voronoi mesh, a much more general and adaptive mesh with respect to the Cartesian one.\n",
        "\n",
        "![voronoi](https://github.com/EGaraldi/EPIC_5/blob/main/Tutorials/tutorial_5/voronoi.png?raw=1)\n",
        "\n",
        "Even better, this mesh adapts to the gas flow, so that it's resolution is better where there is more 'action'\n",
        "\n",
        "![khi](https://github.com/EGaraldi/EPIC_5/blob/main/Tutorials/tutorial_5/khi_arepo.png?raw=1)\n",
        "![gal](https://github.com/EGaraldi/EPIC_5/blob/main/Tutorials/tutorial_5/gal_arepo.png?raw=1)\n",
        "\n",
        "Each one of the cells contains a single value for each of the quantity describing the fluid. For example, it might contain: density, velocity and temperature. But only one value for each of these is allowed in each cell.\n",
        "\n",
        "### Dark Matter\n",
        "Dark Matter is a mysterious substance that makes up 80% of the mass in the Universe. It seems to interact only through gravity (so, no light, no electro-magnetic fields, etc.). Because of this, it is NOT a fluid. AREPO represents it using particles. These are not fundamental particles, but rather represent large \"pieces\" of the Universe. Often these \"pieces\" are millions of time larger than the solar system, but still tiny compared to (most) galaxies. These particles have, by construction, all the same mass.\n",
        "\n",
        "### Stars\n",
        "Stars are also represented using particles. In reality, stars are large spheres of self-gravitating, nuclear burning gas. In fact, we can use CFD codes (including AREPO) to simulate them. But they are so tiny compared to a galaxy or the entire Universe, that they are often represented by particles that interact through gravity only. (Stellar collision are so incredibly rare that they do not matter at the scales of these simulations)\n",
        "\n",
        "### Black hole, tracers, low-res particles, ...\n",
        "There are many more \"things\" that can be simulated in AREPO. For today, we are going to ignore them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b7ed8a",
      "metadata": {},
      "source": [
        "## Solving equations\n",
        "\n",
        "### gravity \n",
        "All components of the simulation interact through gravity. The gravitational force between two bodies 1 and 2 is:\n",
        "\n",
        "$$F_{grav} = G \\frac{M_1 \\, M_2}{r_{12}^2}$$\n",
        "\n",
        "If we have N bodies $i = 1, 2, 3, ..., N$, the number of force computations is: $N(N-1)/2$, i.e. the problem scales as $\\mathcal{O}(N^2)$. This makes the simulation very slow!\n",
        "\n",
        "To make it faster, cosmological simulations often use approximate methods. For example:\n",
        "**particle-mesh**: \n",
        "* compute the mass density $\\rho$ on a 3D grid (think of a 3D histogram of the particle mass)\n",
        "* solve the Poisson equation on this grid to get the gravitational potential $\\Phi$\n",
        "$$ \\nabla^2 \\phi = 4\\pi G \\rho $$\n",
        "* use $\\Phi$ to compute $F_g = -m \\nabla \\Phi $\n",
        "* very fast ($\\mathcal{O}(N \\log N)$), not very accurate close to particles because of resolution effects\n",
        "\n",
        "**oct-tree**:\n",
        "* arrange all particles in an oct-tree structure\n",
        "![octtree](https://devforum-uploads.s3.dualstack.us-east-2.amazonaws.com/uploads/optimized/5X/e/c/4/3/ec4384970592733fa1afd8d3b5c726fd23d74e46_2_690x419.png)\n",
        "* for distant nodes, use the full oct-tree node instead of the particles inside\n",
        "$$ F_{grav} = \\sum_{i \\in node} G \\frac{M_0 \\, M_i}{r_{0i}^2} \\approx G \\frac{M_0 \\, M_{node}}{r_{0node}^2}$$\n",
        "* fast ($\\mathcal{O}(N \\log N)$), but less efficient than particle-mesh\n",
        "\n",
        "AREPO uses a hybrid treePM algorithm, using oct-tree calculations at small scales and particle-mesh calculation at large distances.\n",
        "\n",
        "### gas (fluid equations)\n",
        "\n",
        "This approach is called _finite volumes_ approach, and is conceptually very different from the _finite differences_ method we saw yesterday. Why?\n",
        "\n",
        "**Finite Differences**:\n",
        "* Use grid points to approximate functions, derivatives, etc.\n",
        "* Solves equations at the grid points.\n",
        "* Best suited for structured (regular) grids.\n",
        "\n",
        "**Finite Volumes**:\n",
        "* Divides the domain into small control volumes (cells)\n",
        "* Applies (\"solves\") conservation laws to each volume, tracking the flux of quantities across the boundaries of each cell.\n",
        "* Naturally conserves quantities and works well with unstructured or adaptive meshes (like Voronoi meshes in AREPO).\n",
        "* The solution is the average value within each cell, not at points.\n",
        "\n",
        "In finite volume methods, we have to figure out if and how much of each quantity is transported across _each interface between cells_. This is called a Riemann problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0ca39e6",
      "metadata": {
        "id": "c0ca39e6"
      },
      "source": [
        "## Data format\n",
        "AREPO outputs are in the [HDF5 format](https://www.hdfgroup.org/).\n",
        "\n",
        "Like most simulations of structure formation, has two main types of outputs (but there can be many more):\n",
        "* **snapshots**: full outputs storing the individual resolution elements of the simulation: (Voronoi) mesh, dark matter partcles, stellar particles, ...\n",
        "* **groups catalog**: collection of structures found in the simulation\n",
        "\n",
        "\n",
        "### Snapshot\n",
        "A snapshot, in practice, is an HDF5 file with different HDF5 Groups. One group, called `Header` contains meta-data about the file itself and the simulation that produced it. Another one (`Config`) contains the setup of AREPO used for the simulation. Each other group contains the data concerning one type of resolution element. These groups are named `PartTypeN`, with `N` starting from 0 and increasing. The table below shows what each type `N` represents.\n",
        "  | Type | Meaning     |\n",
        "  | ---- | ----------- |\n",
        "  | 0    | Gas         |\n",
        "  | 1    | Dark Matter |\n",
        "  | 4    | Stars       |\n",
        "  | 5    | Black holes |\n",
        "\n",
        "Each particle type has a number of fields associated, that changes for each type. We will see below how to find out which one are available.\n",
        "- If all particles of one type have the same mass, this is not saved in the fields, but rather in the `MassTable` attribute of the `Header` group\n",
        "\n",
        "### Group catalogs\n",
        "The group catalogs contain two types of structures: Groups and Subhalos.\n",
        "* **Groups or haloes** represent collections of particles that are close to each other, but there is no guarantee that they are physically associated.\n",
        "* **Subhaloes** represent collections of particles that are physically bound to each other. We usually think of these as galaxies.\n",
        "In both cases, the halo catalogs contain only the _summary properties_ of these collections. For example, the _total_ mass of the subhalo, the average temperature, etc.\n",
        "\n",
        "### Units\n",
        "Each field has its own units. They are defined in terms of the code _internal_ units, which are:\n",
        "* Unit of length = $U_L$ = 1 kpc/$h$ = 3.08567e19 m/$h$\n",
        "* Unit of Mass = $U_M$ = 1e10 Msun/$h$ = 1.98847e30 kg/$h$\n",
        "* Unit of Velocity = $U_V$ = 1 km/s = 1e3 m/s\n",
        "\n",
        "Here, $h=0.6774$ is something called _reduced Hubble constant_ and is a measure of how quickly the Universe expands. For today, we do not care about it.\n",
        "\n",
        "Other units can be derived from these. So, for example, the unit of time is:\n",
        "\n",
        "$$U_T = \\frac{U_L}{U_V} = \\frac{3.08567 \\times 10^{19} \\,m/h}{10^3\\, m/s} = 3.08567 \\times 10^{16} s/h = 9.78 \\times 10^8 \\, years/h$$\n",
        "\n",
        "### File chunks\n",
        "For efficiency reasons, a single snapshot or group catalog is often split into multiple _chunks_ that must be combined to obtain the full information. For today, the details are not important because we will use a library that does this for us.\n",
        "\n",
        "\n",
        "### More info\n",
        "- AREPO wiki (for public version only, but almost identical for the private version as well): https://gitlab.mpcdf.mpg.de/vrs/arepo/-/wikis/userguide/snapshotformat\n",
        "- IllustrisTNG data specification: https://www.tng-project.org/data/docs/specifications/\n",
        "- Thesan data specification: https://thesan-project.com/data.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e3712a1",
      "metadata": {
        "id": "3e3712a1"
      },
      "source": [
        "## Libraries\n",
        "There are a few python libraries that can simplify the task of loading these data. For today's tutorial, we will use the [illustris_python](https://github.com/illustristng/illustris_python) library. You can install it in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "451351af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "451351af",
        "outputId": "10cb527b-aa58-482a-9c82-2ff514437242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/illustristng/illustris_python.git\n",
            "  Cloning https://github.com/illustristng/illustris_python.git to /tmp/pip-req-build-iulrqrux\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/illustristng/illustris_python.git /tmp/pip-req-build-iulrqrux\n",
            "  Resolved https://github.com/illustristng/illustris_python.git to commit 2750c7d78270df78b3b3cd1c9e96eacc7512b59d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from illustris_python==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from illustris_python==1.0.0) (3.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from illustris_python==1.0.0) (1.17.0)\n",
            "Building wheels for collected packages: illustris_python\n",
            "  Building wheel for illustris_python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for illustris_python: filename=illustris_python-1.0.0-py3-none-any.whl size=15274 sha256=ac974de9aa81d53fe68a77d0d0661351b519317d529a46de376c9c11ab50058a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9hik35wq/wheels/86/e4/00/01ba77a18a39023ada98456194fcef8898c3484b7136857a78\n",
            "Successfully built illustris_python\n",
            "Installing collected packages: illustris_python\n",
            "Successfully installed illustris_python-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade \"git+https://github.com/illustristng/illustris_python.git\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31dc86bf",
      "metadata": {
        "id": "31dc86bf"
      },
      "source": [
        "## Additional resources\n",
        "- AREPO wiki: https://gitlab.mpcdf.mpg.de/vrs/arepo/-/wikis/home\n",
        "- code paper: https://arxiv.org/abs/0901.4107\n",
        "- further development paper: https://arxiv.org/pdf/1503.00562\n",
        "- RT solver paper: https://academic.oup.com/mnras/article/485/1/117/5303742\n",
        "- introduction to the code (by me):  https://datashare.mpcdf.mpg.de/s/TmjvOoDm4Nm4Pnv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa28bf32",
      "metadata": {
        "id": "aa28bf32"
      },
      "source": [
        "# Step 1: simple data exploration\n",
        "Let's start by simply checking the data we have available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "199a9d7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "199a9d7f",
        "outputId": "68f8736e-e2e2-4cbc-c74d-4ca4da1caec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SNAPSHOT FILE\n",
            "HDF5 groups available:\n",
            " - Config\n",
            " - Header\n",
            " - Parameters\n",
            " - PartType0\n",
            " - PartType1\n",
            " - PartType4\n",
            " - PartType5\n",
            "\n",
            "Attributes in the Header group:\n",
            " - BoxSize: 75000.0\n",
            " - Composition_vector_length: 0\n",
            " - Flag_Cooling: 1\n",
            " - Flag_DoublePrecision: 0\n",
            " - Flag_Feedback: 1\n",
            " - Flag_Metals: 0\n",
            " - Flag_Sfr: 1\n",
            " - Flag_StellarAge: 0\n",
            " - Git_commit: b'd203ec8b07c7e2bdda5f608aa0babea46d603699'\n",
            " - Git_date: b'Thu Apr 7 14:14:27 2016 +0200'\n",
            " - HubbleParam: 0.6774\n",
            " - MassTable: [0.         0.03235675 0.         0.00302063 0.         0.        ]\n",
            " - NumFilesPerSnapshot: 7\n",
            " - NumPart_ThisFile: [12687804 13349540        0        0   329031     4397]\n",
            " - NumPart_Total: [88953586 94196375        0        0  2234312    30546]\n",
            " - NumPart_Total_HighWord: [0 0 0 0 0 0]\n",
            " - Omega0: 0.3089\n",
            " - OmegaBaryon: 0.0486\n",
            " - OmegaLambda: 0.6911\n",
            " - Redshift: 0.009521666967944764\n",
            " - Time: 0.99056814006128\n",
            " - UnitLength_in_cm: 3.085678e+21\n",
            " - UnitMass_in_g: 1.989e+43\n",
            " - UnitVelocity_in_cm_per_s: 100000.0\n",
            "\n",
            "Particle type: PartType0\n",
            " - Coordinates: shape (12687804, 3), dtype float32\n",
            " - Density: shape (12687804,), dtype float32\n",
            " - ElectronAbundance: shape (12687804,), dtype float32\n",
            " - GFM_Metallicity: shape (12687804,), dtype float32\n",
            " - InternalEnergy: shape (12687804,), dtype float32\n",
            " - InternalEnergyOld: shape (12687804,), dtype float32\n",
            " - Masses: shape (12687804,), dtype float32\n",
            " - ParticleIDs: shape (12687804,), dtype uint64\n",
            " - StarFormationRate: shape (12687804,), dtype float32\n",
            " - Velocities: shape (12687804, 3), dtype float32\n",
            "\n",
            "Particle type: PartType1\n",
            " - Coordinates: shape (13349540, 3), dtype float32\n",
            " - ParticleIDs: shape (13349540,), dtype uint64\n",
            " - Velocities: shape (13349540, 3), dtype float32\n",
            "\n",
            "Particle type: PartType4\n",
            " - Coordinates: shape (329031, 3), dtype float32\n",
            " - GFM_InitialMass: shape (329031,), dtype float32\n",
            " - GFM_Metallicity: shape (329031,), dtype float32\n",
            " - GFM_StellarFormationTime: shape (329031,), dtype float32\n",
            " - Masses: shape (329031,), dtype float32\n",
            " - ParticleIDs: shape (329031,), dtype uint64\n",
            " - Potential: shape (329031,), dtype float32\n",
            " - StellarHsml: shape (329031,), dtype float32\n",
            " - Velocities: shape (329031, 3), dtype float32\n",
            "\n",
            "Particle type: PartType5\n",
            " - BH_BPressure: shape (4397,), dtype float32\n",
            " - BH_CumEgyInjection_QM: shape (4397,), dtype float32\n",
            " - BH_CumEgyInjection_RM: shape (4397,), dtype float32\n",
            " - BH_CumMassGrowth_QM: shape (4397,), dtype float32\n",
            " - BH_CumMassGrowth_RM: shape (4397,), dtype float32\n",
            " - BH_Density: shape (4397,), dtype float32\n",
            " - BH_HostHaloMass: shape (4397,), dtype float32\n",
            " - BH_Hsml: shape (4397,), dtype float32\n",
            " - BH_Mass: shape (4397,), dtype float32\n",
            " - BH_Mdot: shape (4397,), dtype float32\n",
            " - BH_MdotBondi: shape (4397,), dtype float32\n",
            " - BH_MdotEddington: shape (4397,), dtype float32\n",
            " - BH_Pressure: shape (4397,), dtype float32\n",
            " - BH_Progs: shape (4397,), dtype uint32\n",
            " - BH_U: shape (4397,), dtype float32\n",
            " - Coordinates: shape (4397, 3), dtype float32\n",
            " - Masses: shape (4397,), dtype float32\n",
            " - ParticleIDs: shape (4397,), dtype uint64\n",
            " - Potential: shape (4397,), dtype float32\n",
            " - Velocities: shape (4397, 3), dtype float32\n",
            "\n",
            "\n",
            "GROUP FILE\n",
            "HDF5 groups available:\n",
            " - Config\n",
            " - Group\n",
            " - Header\n",
            " - IDs\n",
            " - Parameters\n",
            " - Subhalo\n",
            "\n",
            "Group datasets\n",
            " - GroupBHMass: shape (15,), dtype float32\n",
            " - GroupBHMdot: shape (15,), dtype float32\n",
            " - GroupCM: shape (15, 3), dtype float32\n",
            " - GroupFirstSub: shape (15,), dtype int32\n",
            " - GroupGasMetalFractions: shape (15, 10), dtype float32\n",
            " - GroupGasMetallicity: shape (15,), dtype float32\n",
            " - GroupLen: shape (15,), dtype int32\n",
            " - GroupLenType: shape (15, 6), dtype int32\n",
            " - GroupMass: shape (15,), dtype float32\n",
            " - GroupMassType: shape (15, 6), dtype float32\n",
            " - GroupNsubs: shape (15,), dtype int32\n",
            " - GroupPos: shape (15, 3), dtype float32\n",
            " - GroupSFR: shape (15,), dtype float32\n",
            " - GroupStarMetalFractions: shape (15, 10), dtype float32\n",
            " - GroupStarMetallicity: shape (15,), dtype float32\n",
            " - GroupVel: shape (15, 3), dtype float32\n",
            " - GroupWindMass: shape (15,), dtype float32\n",
            " - Group_M_Crit200: shape (15,), dtype float32\n",
            " - Group_M_Crit500: shape (15,), dtype float32\n",
            " - Group_M_Mean200: shape (15,), dtype float32\n",
            " - Group_M_TopHat200: shape (15,), dtype float32\n",
            " - Group_R_Crit200: shape (15,), dtype float32\n",
            " - Group_R_Crit500: shape (15,), dtype float32\n",
            " - Group_R_Mean200: shape (15,), dtype float32\n",
            " - Group_R_TopHat200: shape (15,), dtype float32\n",
            "\n",
            "Subhalo datasets\n",
            " - SubhaloBHMass: shape (3827,), dtype float32\n",
            " - SubhaloBHMdot: shape (3827,), dtype float32\n",
            " - SubhaloCM: shape (3827, 3), dtype float32\n",
            " - SubhaloFlag: shape (3827,), dtype bool\n",
            " - SubhaloGasMetalFractions: shape (3827, 10), dtype float32\n",
            " - SubhaloGasMetalFractionsHalfRad: shape (3827, 10), dtype float32\n",
            " - SubhaloGasMetalFractionsMaxRad: shape (3827, 10), dtype float32\n",
            " - SubhaloGasMetalFractionsSfr: shape (3827, 10), dtype float32\n",
            " - SubhaloGasMetalFractionsSfrWeighted: shape (3827, 10), dtype float32\n",
            " - SubhaloGasMetallicity: shape (3827,), dtype float32\n",
            " - SubhaloGasMetallicityHalfRad: shape (3827,), dtype float32\n",
            " - SubhaloGasMetallicityMaxRad: shape (3827,), dtype float32\n",
            " - SubhaloGasMetallicitySfr: shape (3827,), dtype float32\n",
            " - SubhaloGasMetallicitySfrWeighted: shape (3827,), dtype float32\n",
            " - SubhaloGrNr: shape (3827,), dtype int32\n",
            " - SubhaloHalfmassRad: shape (3827,), dtype float32\n",
            " - SubhaloHalfmassRadType: shape (3827, 6), dtype float32\n",
            " - SubhaloIDMostbound: shape (3827,), dtype uint64\n",
            " - SubhaloLen: shape (3827,), dtype int32\n",
            " - SubhaloLenType: shape (3827, 6), dtype int32\n",
            " - SubhaloMass: shape (3827,), dtype float32\n",
            " - SubhaloMassInHalfRad: shape (3827,), dtype float32\n",
            " - SubhaloMassInHalfRadType: shape (3827, 6), dtype float32\n",
            " - SubhaloMassInMaxRad: shape (3827,), dtype float32\n",
            " - SubhaloMassInMaxRadType: shape (3827, 6), dtype float32\n",
            " - SubhaloMassInRad: shape (3827,), dtype float32\n",
            " - SubhaloMassInRadType: shape (3827, 6), dtype float32\n",
            " - SubhaloMassType: shape (3827, 6), dtype float32\n",
            " - SubhaloParent: shape (3827,), dtype int32\n",
            " - SubhaloPos: shape (3827, 3), dtype float32\n",
            " - SubhaloSFR: shape (3827,), dtype float32\n",
            " - SubhaloSFRinHalfRad: shape (3827,), dtype float32\n",
            " - SubhaloSFRinMaxRad: shape (3827,), dtype float32\n",
            " - SubhaloSFRinRad: shape (3827,), dtype float32\n",
            " - SubhaloSpin: shape (3827, 3), dtype float32\n",
            " - SubhaloStarMetalFractions: shape (3827, 10), dtype float32\n",
            " - SubhaloStarMetalFractionsHalfRad: shape (3827, 10), dtype float32\n",
            " - SubhaloStarMetalFractionsMaxRad: shape (3827, 10), dtype float32\n",
            " - SubhaloStarMetallicity: shape (3827,), dtype float32\n",
            " - SubhaloStarMetallicityHalfRad: shape (3827,), dtype float32\n",
            " - SubhaloStarMetallicityMaxRad: shape (3827,), dtype float32\n",
            " - SubhaloStellarPhotometrics: shape (3827, 8), dtype float32\n",
            " - SubhaloStellarPhotometricsMassInRad: shape (3827,), dtype float32\n",
            " - SubhaloStellarPhotometricsRad: shape (3827,), dtype float32\n",
            " - SubhaloVel: shape (3827, 3), dtype float32\n",
            " - SubhaloVelDisp: shape (3827,), dtype float32\n",
            " - SubhaloVmax: shape (3827,), dtype float32\n",
            " - SubhaloVmaxRad: shape (3827,), dtype float32\n",
            " - SubhaloWindMass: shape (3827,), dtype float32\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "print(\"SNAPSHOT FILE\")\n",
        "with h5py.File(f'tng100-3/output/snapdir_098/snap_098.0.hdf5', 'r') as snapfile:\n",
        "\n",
        "    print(\"HDF5 groups available:\")\n",
        "    for group_name in snapfile.keys():\n",
        "        print(f\" - {group_name}\")\n",
        "    print()\n",
        "\n",
        "    #print the attributes of the 'Header' group\n",
        "    header = snapfile['Header']\n",
        "    print(\"Attributes in the Header group:\")\n",
        "    for attr_name, attr_value in header.attrs.items():\n",
        "        print(f\" - {attr_name}: {attr_value}\")\n",
        "    print()\n",
        "\n",
        "    #print the datasets available for each particle type:\")\n",
        "    for part_type in snapfile.keys():\n",
        "        if part_type.startswith('PartType'):\n",
        "            print(f\"Particle type: {part_type}\")\n",
        "            part_data = snapfile[part_type]\n",
        "            for dataset_name in part_data.keys():\n",
        "                print(f\" - {dataset_name}: shape {part_data[dataset_name].shape}, dtype {part_data[dataset_name].dtype}\")\n",
        "            print()\n",
        "\n",
        "  # Let's do the same for the group catalogs\n",
        "print(\"\\nGROUP FILE\")\n",
        "with h5py.File(f'tng100-3/output/groups_098/fof_subhalo_tab_098.0.hdf5', 'r') as groupfile:\n",
        "\n",
        "  print(\"HDF5 groups available:\")\n",
        "  for group_name in groupfile.keys():\n",
        "      print(f\" - {group_name}\")\n",
        "  print()\n",
        "\n",
        "  #print the dataset available for groups and subhaloes\n",
        "  print('Group datasets')\n",
        "  for dataset_name in groupfile['Group'].keys():\n",
        "      print(f\" - {dataset_name}: shape {groupfile['Group'][dataset_name].shape}, dtype {groupfile['Group'][dataset_name].dtype}\")\n",
        "  print()\n",
        "\n",
        "  print('Subhalo datasets')\n",
        "  for dataset_name in groupfile['Subhalo'].keys():\n",
        "      print(f\" - {dataset_name}: shape {groupfile['Subhalo'][dataset_name].shape}, dtype {groupfile['Subhalo'][dataset_name].dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e25da1f",
      "metadata": {
        "id": "0e25da1f"
      },
      "outputs": [],
      "source": [
        "with h5py.File('tng100-3/output/snapdir_098/snap_098.0.hdf5', 'r') as snapfile:\n",
        "    print(snapfile['PartType0/Coordinates'][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a396c1e7",
      "metadata": {
        "id": "a396c1e7"
      },
      "source": [
        "## File chunks and illustris_python\n",
        "As mentioned, snapshot files are split in chunks, each one with (potentially) a different number of particles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "014ada0c",
      "metadata": {
        "id": "014ada0c"
      },
      "outputs": [],
      "source": [
        "with h5py.File('tng100-3/output/snapdir_098/snap_098.0.hdf5', 'r') as snapfile:\n",
        "    Nfiles = snapfile['Header'].attrs['NumFilesPerSnapshot']\n",
        "\n",
        "for ifile in range(Nfiles):\n",
        "    with h5py.File(f'tng100-3/output/snapdir_098/snap_098.{ifile}.hdf5', 'r') as snapfile:\n",
        "        print(f\"File {ifile}:\", snapfile['Header'].attrs['NumPart_ThisFile'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a35614de",
      "metadata": {
        "id": "a35614de"
      },
      "source": [
        "So, if we want to load all gas particles, we have to explicitly loop over all files. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8880e2",
      "metadata": {
        "id": "9c8880e2"
      },
      "outputs": [],
      "source": [
        "gas_positions = []\n",
        "\n",
        "for ifile in range(Nfiles):\n",
        "    with h5py.File(f'tng100-3/output/snapdir_098/snap_098.{ifile}.hdf5', 'r') as snapfile:\n",
        "        gas_positions.append(snapfile['PartType0/Coordinates'][:])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73b7c327",
      "metadata": {
        "id": "73b7c327"
      },
      "source": [
        "Or, we can use the `illustris_python` to do this for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bd42f7d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bd42f7d5",
        "outputId": "d24d3143-d2f6-43eb-9046-343df6dee3f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>illustris_python.snapshot.loadSubset</b><br/>def loadSubset(basePath, snapNum, partType, fields=None, subset=None, mdi=None, sq=True, float32=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/illustris_python/snapshot.py</a>Load a subset of fields for all particles/cells of a given partType.\n",
              "If offset and length specified, load only that subset of the partType.\n",
              "If mdi is specified, must be a list of integers of the same length as fields,\n",
              "giving for each field the multi-dimensional index (on the second dimension) to load.\n",
              "  For example, fields=[&#x27;Coordinates&#x27;, &#x27;Masses&#x27;] and mdi=[1, None] returns a 1D array\n",
              "  of y-Coordinates only, together with Masses.\n",
              "If sq is True, return a numpy array instead of a dict if len(fields)==1.\n",
              "If float32 is True, load any float64 datatype arrays directly as float32 (save memory). </pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 38);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<function illustris_python.snapshot.loadSubset(basePath, snapNum, partType, fields=None, subset=None, mdi=None, sq=True, float32=False)>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import illustris_python as il\n",
        "il.snapshot.loadSubset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff20fb6",
      "metadata": {
        "id": "aff20fb6"
      },
      "outputs": [],
      "source": [
        "gas_data = il.snapshot.loadSubset('tng100-3/output', 98, 0, fields=['Coordinates'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a82f0c7",
      "metadata": {
        "id": "7a82f0c7"
      },
      "source": [
        "# Step 2: visualization\n",
        "Let's start by checking how the simulation _looks like_. Naturally, the final results depends on what and how we plot. And naturally, this is not enough for scientific results. But it really helps to understand what is going on in the simulation.\n",
        "\n",
        "For example, we can just plot all gas particles in the simulation.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce713086",
      "metadata": {
        "id": "ce713086"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.scatter(gas_data['Coordinates'][:, 0], gas_data['Coordinates'][:, 1], s=0.001, c='k', alpha=0.1)\n",
        "ax.set_axis_off()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "526f84ee",
      "metadata": {
        "id": "526f84ee"
      },
      "source": [
        "That's a mess! There's too many particles because we are projecting all particles along the $z$ direction! We can do better.."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0c263b8",
      "metadata": {
        "id": "d0c263b8"
      },
      "source": [
        "## Slice\n",
        "A slice is simply a plot of all particles/grid cells/etc in a _slice_ through the simulation box, or one of their properties. The simplest thing we can do, is just to plot one dot per particle.\n",
        "\n",
        "Try to adjust the code above to make a slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6c888bb",
      "metadata": {
        "id": "d6c888bb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# your code here\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.scatter(gas_data['Coordinates'][slice_mask, 0], gas_data['Coordinates'][slice_mask, 1], s=0.001, c='k', alpha=0.1)\n",
        "ax.set_axis_off()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c205849e",
      "metadata": {
        "id": "c205849e"
      },
      "source": [
        "We can see the **cosmic web**! But the dense parts are saturated because there are too many particles close to each other. We can fix this in few ways:\n",
        "* play with point size and transparency\n",
        "* make the slice thinner\n",
        "* change how we plot this\n",
        "\n",
        "**Exercise**: use a 2D histogram instead of `scatter` to make a map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1031c020",
      "metadata": {
        "id": "1031c020"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "min_z = 50000\n",
        "max_z = 60000\n",
        "\n",
        "slice_mask = (gas_data['Coordinates'][:, 2] >= min_z) & (gas_data['Coordinates'][:, 2] < max_z)\n",
        "\n",
        "with h5py.File('tng100-3/output/snapdir_098/snap_098.0.hdf5', 'r') as snapfile:\n",
        "    Lbox = snapfile['Header'].attrs['BoxSize']\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "h2d, _, _ = np.histogram2d(gas_data['Coordinates'][slice_mask, 0], gas_data['Coordinates'][slice_mask, 1], bins=300)\n",
        "ax.imshow(np.log10(h2d.T + 1), origin='lower', cmap='viridis', extent=(0, Lbox, 0, Lbox))\n",
        "ax.set_axis_off()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff115b90",
      "metadata": {
        "id": "ff115b90"
      },
      "source": [
        "Now the color shows the gas density! We can see that there are clumps of matter (in yellow) at the nodes of this web. These are the haloes we were talking about earlier. To convince ourselves, let's mark them.\n",
        "\n",
        "First, we can load the haloes in the simulation using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e92458a",
      "metadata": {
        "id": "9e92458a"
      },
      "outputs": [],
      "source": [
        "il.groupcat.loadHalos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47dbb8e8",
      "metadata": {
        "id": "47dbb8e8"
      },
      "outputs": [],
      "source": [
        "group_data = il.groupcat.loadHalos('tng100-3/output', 98, fields=['GroupPos'])\n",
        "slice_mask_groups = (group_data['GroupPos'][:, 2] >= min_z) & (group_data['GroupPos'][:, 2] < max_z)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "h2d, _, _ = np.histogram2d(gas_data['Coordinates'][slice_mask, 0], gas_data['Coordinates'][slice_mask, 1], bins=300)\n",
        "ax.imshow(np.log10(h2d.T + 1), origin='lower', cmap='viridis', extent=(0, Lbox, 0, Lbox))\n",
        "\n",
        "ax.scatter(group_data['GroupPos'][slice_mask_groups, 0], group_data['GroupPos'][slice_mask_groups, 1], marker='x', c='r', s=0.1)\n",
        "\n",
        "ax.set_axis_off()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e22a70d",
      "metadata": {
        "id": "5e22a70d"
      },
      "source": [
        "### Exercise: plot other physical quantities\n",
        "Using a 2D histogram makes it easy to show different physical quantities. Try to plot different properties of the gas, or different types of particles (dark matter, stars, black holes)\n",
        "\n",
        "**Hint**: to do this, you need to first load the gas properties. Have a look at the list of available properties from before, then load them alongside the positions, and use them for plotting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32d58a7",
      "metadata": {
        "id": "e32d58a7"
      },
      "source": [
        "### Periodic Boundary Conditions\n",
        "Cosmological simulations often use PBC. This is the simplest way to simulate an 'infinite' Universe. I practice, it means that if a particle crosses one edge of the simulation, it \"enters\" from the opposite side.\n",
        "\n",
        "This also means that we can shift the center of the particle distribution to any point we want. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b157173b",
      "metadata": {
        "id": "b157173b"
      },
      "outputs": [],
      "source": [
        "def shift_center(positions, new_center):\n",
        "    #your code here\n",
        "    #hint: the new_center is a 3D vector, and the current center is at [0.5, 0.5, 0.5]* Lbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4174126",
      "metadata": {
        "id": "f4174126"
      },
      "outputs": [],
      "source": [
        "new_pos = shift_center(gas_data['Coordinates'], np.array([0.7, 0.3, 0.5])*Lbox)\n",
        "\n",
        "slice_mask = (new_pos[:, 2] >= min_z) & (new_pos[:, 2] < max_z)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "h2d, _, _ = np.histogram2d(new_pos[slice_mask, 0], new_pos[slice_mask, 1], bins=300, weights=gas_data['GFM_Metallicity'][slice_mask])\n",
        "ax.imshow(np.log10(h2d.T + 1), origin='lower', cmap='inferno', extent=(0, Lbox, 0, Lbox))\n",
        "ax.set_axis_off()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c02d5d2",
      "metadata": {
        "id": "0c02d5d2"
      },
      "source": [
        "## Individual galaxies\n",
        "We can try now to visualize individual galaxies. For this, we have to:\n",
        "* identify where galaxies are, using the group catalogs\n",
        "* load all and only the particles that belong to a galaxy, using group catalogs + snapshots\n",
        "* visualize them\n",
        "\n",
        "We can use illustris_python to do the first two steps for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f6472b9",
      "metadata": {
        "id": "1f6472b9"
      },
      "outputs": [],
      "source": [
        "il.snapshot.loadSubhalo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d738f39",
      "metadata": {
        "id": "2d738f39"
      },
      "outputs": [],
      "source": [
        "subhalo_id = 0\n",
        "\n",
        "galaxy_data_gas   = il.snapshot.loadSubhalo('tng100-3/output', 98, subhalo_id, 0, fields=['Coordinates', 'Density', 'Velocities', 'GFM_Metallicity', 'InternalEnergy'])\n",
        "galaxy_data_stars = il.snapshot.loadSubhalo('tng100-3/output', 98, subhalo_id, 4, fields=['Coordinates', 'GFM_StellarFormationTime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3cb2f58",
      "metadata": {
        "id": "f3cb2f58"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "h2d, _, _ = np.histogram2d(galaxy_data_gas['Coordinates'][:, 0], galaxy_data_gas['Coordinates'][:, 1], bins=100)\n",
        "ax.imshow(np.log10(h2d.T + 1), origin='lower', cmap='viridis', aspect='auto',\n",
        "          extent=(galaxy_data_gas['Coordinates'][:, 0].min(), galaxy_data_gas['Coordinates'][:, 0].max(), galaxy_data_gas['Coordinates'][:, 1].min(), galaxy_data_gas['Coordinates'][:, 1].max()))\n",
        "ax.scatter(galaxy_data_stars['Coordinates'][:, 0], galaxy_data_stars['Coordinates'][:, 1], marker='*', s=0.1, c='r')\n",
        "\n",
        "ax.set_axis_off()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88882f03",
      "metadata": {
        "id": "88882f03"
      },
      "source": [
        "### Question: What is happening?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34af5374",
      "metadata": {
        "id": "34af5374"
      },
      "outputs": [],
      "source": [
        "#center the galaxy\n",
        "subhalo_data = il.groupcat.loadSubhalos('tng100-3/output', 98, fields=['SubhaloPos', 'SubhaloMassInRadType', 'SubhaloHalfmassRadType'])\n",
        "galaxy_center = subhalo_data['SubhaloPos'][subhalo_id]\n",
        "galaxy_data_gas['Coordinates']   = shift_center(galaxy_data_gas['Coordinates'], galaxy_center)\n",
        "galaxy_data_stars['Coordinates'] = shift_center(galaxy_data_stars['Coordinates'], galaxy_center)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e4558c2",
      "metadata": {
        "id": "5e4558c2"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "h2d, _, _ = np.histogram2d(galaxy_data_gas['Coordinates'][:, 0], galaxy_data_gas['Coordinates'][:, 1], bins=100)\n",
        "ax.imshow(np.log10(h2d.T + 1), origin='lower', cmap='viridis', aspect='auto',\n",
        "          extent=(galaxy_data_gas['Coordinates'][:, 0].min(), galaxy_data_gas['Coordinates'][:, 0].max(), galaxy_data_gas['Coordinates'][:, 1].min(), galaxy_data_gas['Coordinates'][:, 1].max()))\n",
        "ax.scatter(galaxy_data_stars['Coordinates'][:, 0], galaxy_data_stars['Coordinates'][:, 1], marker='*', s=0.1, c='r')\n",
        "\n",
        "ax.set_axis_off()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca0e7fcd",
      "metadata": {
        "id": "ca0e7fcd"
      },
      "source": [
        "This shows us an important feture of galaxies. Stars are usually much more concentrated than gas! If you are not convinced, try changing the subhalo number and see!\n",
        "\n",
        "## Stars\n",
        "Now let's have a closer look at the stars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38694366",
      "metadata": {
        "id": "38694366"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "selection = np.full_like(galaxy_data_stars['Coordinates'][:, 0], True, dtype=bool) #all particles\n",
        "\n",
        "h2d, _, _ = np.histogram2d(galaxy_data_stars['Coordinates'][selection, 0], galaxy_data_stars['Coordinates'][selection, 1], bins=100)\n",
        "ax.imshow(np.log10(h2d.T + 1), origin='lower', cmap='cividis', aspect='auto',\n",
        "          extent=(galaxy_data_stars['Coordinates'][selection, 0].min(), galaxy_data_stars['Coordinates'][selection, 0].max(), galaxy_data_stars['Coordinates'][selection, 1].min(), galaxy_data_stars['Coordinates'][selection, 1].max()))\n",
        "\n",
        "ax.set_axis_off()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fae8ee36",
      "metadata": {
        "id": "fae8ee36"
      },
      "source": [
        "### Exercise: plot galaxy radius\n",
        "\n",
        "We can define the radius of a galaxy using the `SubhaloHalfmassRadType` property of the subhalo. This gives us the radius that contains half the particles of each type. Since most of the time we see just the stars in the galaxy, we will use them to define a radius.\n",
        "\n",
        "Your tasks:\n",
        "* find the galaxy stellar radius\n",
        "* plot only stars that are within this galaxy radius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3a771b",
      "metadata": {
        "id": "cf3a771b"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31c0fc4",
      "metadata": {
        "id": "e31c0fc4"
      },
      "source": [
        "### hot vs cold gas\n",
        "\n",
        "The gas can have very different temperatures. Following the laws of thermodynamics, cold gas is dense while hot gas is rarefied.\n",
        "\n",
        "Stars when gas collapses under its own gravity. Therefore, stars form in dense, cold gas. The energy they produce (radiation, winds, etc.) heats up the gas around them. This gas eventually cools down again and forms new stars.\n",
        "\n",
        "AREPO does not save the gas temperature directly, but saves instead the internal (thermal) energy _per unit mass_, so we need a conversion to get the temperature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77bbf41d",
      "metadata": {
        "id": "77bbf41d"
      },
      "outputs": [],
      "source": [
        "def computeParticlesTemperature(u, UnitVelocity_in_cm_per_s = 1e5, MeanMolecularWeight = 1, gamma = 5/3):\n",
        "    \"\"\"\n",
        "    compute the temperature of the (gas) particles from their internal energy\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    u : numpy.array of float\n",
        "        internal energy of the particles (as read from GADGET file). shape=(Npart)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    temp : numpy.array of float\n",
        "           temperature of the particles\n",
        "    \"\"\"\n",
        "\n",
        "    BOLTZMANN = 1.3806e-16\n",
        "    # units of u are energy/mass = (mass*length2/time2)/mass = (mass*length2/(length/velocity)2)/mass = velocity2\n",
        "    PROTONMASS = 1.6726e-24  # g\n",
        "    temp = MeanMolecularWeight*PROTONMASS/BOLTZMANN * (gamma-1) * u * UnitVelocity_in_cm_per_s**2\n",
        "\n",
        "    return temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c3da39f",
      "metadata": {
        "id": "1c3da39f"
      },
      "outputs": [],
      "source": [
        "galaxy_data_gas['Temperature'] = computeParticlesTemperature(galaxy_data_gas['InternalEnergy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f69bb95",
      "metadata": {
        "id": "8f69bb95"
      },
      "source": [
        "and we can finally plot the gas temperature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3badfaf",
      "metadata": {
        "id": "c3badfaf"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "h2d, _, _ = np.histogram2d(galaxy_data_gas['Coordinates'][:, 0], galaxy_data_gas['Coordinates'][:, 1], bins=100, weights=galaxy_data_gas['Density']*galaxy_data_gas['Temperature'])\n",
        "ax.imshow(np.log10(h2d.T + 1), origin='lower', cmap='inferno', aspect='auto',\n",
        "          extent=(galaxy_data_gas['Coordinates'][:, 0].min(), galaxy_data_gas['Coordinates'][:, 0].max(), galaxy_data_gas['Coordinates'][:, 1].min(), galaxy_data_gas['Coordinates'][:, 1].max()))\n",
        "\n",
        "ax.set_axis_off()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05fcbd2f",
      "metadata": {
        "id": "05fcbd2f"
      },
      "source": [
        "### Exercise: plot hot and cold gas separately\n",
        "\n",
        "For this, let's say that:\n",
        "* cold gas = gas with $T \\leq 10^6$ K\n",
        "* hot gas = gas with $T > 10^6$ K\n",
        "\n",
        "hint: use the temperature to select the gas to plot, then use a 2d histogram to show plot it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a6d265",
      "metadata": {
        "id": "88a6d265"
      },
      "outputs": [],
      "source": [
        "#your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed0e9774",
      "metadata": {
        "id": "ed0e9774"
      },
      "source": [
        "# Step 3: Phase-space diagram\n",
        "\n",
        "Let's move to some quantitative analysis. A powerful tool is called **phase-space diagram**. This is the distribution of gas density and temperature in the simulation. From it, we can learn a lot about what the gas does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab155c4",
      "metadata": {
        "id": "1ab155c4"
      },
      "outputs": [],
      "source": [
        "gas_data = il.snapshot.loadSubset('tng100-3/output', 98, 0, fields=['Density', 'InternalEnergy'])\n",
        "gas_data['Temperature'] = computeParticlesTemperature(gas_data['InternalEnergy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e24bef28",
      "metadata": {
        "id": "e24bef28"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.hist2d(np.log10(gas_data['Density']), np.log10(gas_data['Temperature']), norm=LogNorm(), bins=100, cmap='viridis')\n",
        "\n",
        "ax.set_xlabel(r'log$_{10}$(gas density)', fontsize=20)\n",
        "ax.set_ylabel(r'log$_{10}$(gas temperature)', fontsize=20)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2274652",
      "metadata": {
        "id": "d2274652"
      },
      "source": [
        "We can identify many different regions:\n",
        "* equation of state gas\n",
        "* hot diffuse gas produced by supernova\n",
        "* warm gas produced by photo-ionisation\n",
        "* the _baryon cycle_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5af6fbd",
      "metadata": {
        "id": "b5af6fbd"
      },
      "source": [
        "# Step 4: Halo mass function\n",
        "The halo mass function (HMF) is a basic characterization of how many haloes (collapsed structures) exist as a function of their mass.\n",
        "\n",
        "The HMF is important for many reasons, including:\n",
        "\n",
        "* Testing Cosmological Models: the HMF changes depending on the amount of dark and non-dark matter in the Universe, how fast it is expanding, _what is_ dark matter, etc. We can compare the predicted HMF with observations to understand the composition of the Universe.\n",
        "* Structure Formation: halos are the building blocks of cosmic structure. Galaxies and clusters of galaxies form within these halos. Knowing the HMF allow us to better understand how galaxies and other visible objects formed after the Big Bang.\n",
        "\n",
        "Specifically, the HMF is defined as the number _density_ of haloes in a given mass range:\n",
        "\n",
        "$$HMF = \\frac{dN(M_0 \\leq M_\\mathrm{halo} < M_1)}{dV \\, d\\log(M)}$$\n",
        "\n",
        "where:\n",
        "* $dN(M_0 \\leq M_\\mathrm{halo} < M_1)$ is the number of haloes with mass between $M_0$ and $M_1$,\n",
        "* $dV$ is the volume used for counting the haloes and\n",
        "* $d\\log(M) = \\log(M_1) - \\log(M_0)$.\n",
        "\n",
        "Here, however, we will use the HMF in a different way, i.e. to test the reliability of our simulation.\n",
        "\n",
        "First of all, let's compute the HMF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a13dead",
      "metadata": {
        "id": "5a13dead"
      },
      "outputs": [],
      "source": [
        "halo_masses = group_data['Group_M_Mean200'] * 1e10 # M_sun/h\n",
        "\n",
        "halo_masses = halo_masses[halo_masses > 0] #need to remove spurious structures\n",
        "\n",
        "# Define bins of halo mass\n",
        "Nbins = 50\n",
        "log_masses = np.log10(halo_masses)\n",
        "min_log_mass = log_masses.min()\n",
        "max_log_mass = log_masses.max()\n",
        "mass_bins = np.linspace(min_log_mass, max_log_mass, Nbins)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# count haloes of given mass and normalize\n",
        "dN, _ = np.histogram(log_masses, bins=mass_bins)\n",
        "dlogM = mass_bins[1] - mass_bins[0]\n",
        "Lbox_in_cMpc = Lbox/1000\n",
        "hmf = dN/dlogM/Lbox_in_cMpc**3\n",
        "\n",
        "ax.step(mass_bins[:-1], np.log10(hmf), where='post', lw=3)\n",
        "\n",
        "ax.set_xlabel(r'$\\log(M_\\mathrm{halo} \\, [M_\\odot/h])$')\n",
        "ax.set_ylabel(r'$\\log(dN/dlogM \\, [h^3 \\, cMpc^{-3}])$')\n",
        "ax.set_title('Halo Mass Function')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TDonsGUuc-ZU",
      "metadata": {
        "id": "TDonsGUuc-ZU"
      },
      "source": [
        "Now let's compare this to some theoretical prediction. For this, we will use the `colossus` python package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oSPgKxzxc58q",
      "metadata": {
        "id": "oSPgKxzxc58q"
      },
      "outputs": [],
      "source": [
        "!pip install colossus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tVfJmn6NdOxX",
      "metadata": {
        "id": "tVfJmn6NdOxX"
      },
      "outputs": [],
      "source": [
        "from colossus.cosmology import cosmology\n",
        "\n",
        "#set the cosmology parameters\n",
        "with h5py.File('tng100-3/output/snapdir_098/snap_098.0.hdf5', 'r') as snapfile:\n",
        "    cosmo_params = {\n",
        "        'flat': True,\n",
        "        'H0': snapfile['Header'].attrs['HubbleParam'] * 100, #units km/s/Mpc\n",
        "        'Om0': snapfile['Header'].attrs['Omega0'],\n",
        "        'Ode0': snapfile['Header'].attrs['OmegaLambda'],\n",
        "        'Ob0': snapfile['Header'].attrs['OmegaBaryon'],\n",
        "        'sigma8': 0.8159,\n",
        "        'ns': 0.9667\n",
        "    }\n",
        "    #for later\n",
        "    redshift = snapfile['Header'].attrs['Redshift']\n",
        "\n",
        "cosmology.setCosmology('myCosmo', cosmo_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ty-jzz0GeBI8",
      "metadata": {
        "id": "ty-jzz0GeBI8"
      },
      "outputs": [],
      "source": [
        "from colossus.lss import mass_function\n",
        "\n",
        "# Colossus expects mass in Msun/h and computes dN/dln(M) -> we need to convert this to dN/dlog10(M)\n",
        "bin_centers = (mass_bins[:-1] + mass_bins[1:]) * 0.5\n",
        "jenkins_mf = mass_function.massFunction(10**bin_centers, redshift, mdef = 'fof', model = 'jenkins01', q_out = 'dndlnM')\n",
        "jenkins_mf *= np.log(10)\n",
        "\n",
        "angulo_mf = mass_function.massFunction(10**bin_centers, redshift, mdef = 'fof', model = 'angulo12', q_out = 'dndlnM')\n",
        "angulo_mf *= np.log(10)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "ax.step(mass_bins[:-1], np.log10(hmf), where='post', lw=3, label='TNG100-3')\n",
        "ax.plot(bin_centers, np.log10(jenkins_mf), color='red', linestyle='--', lw = 3, label='Jenkins (2001)')\n",
        "ax.plot(bin_centers, np.log10(angulo_mf), color='green', linestyle='--', lw = 3, label='Angulo (2012)')\n",
        "\n",
        "ax.legend()\n",
        "ax.set_xlabel('log(M_halo)')\n",
        "ax.set_ylabel('log(dN/dlogM)')\n",
        "ax.set_title('Halo Mass Function')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d-9XVXowdKKC",
      "metadata": {
        "id": "d-9XVXowdKKC"
      },
      "source": [
        "What is causing the big difference on the left side? To get a hint, let's mark the resolution of the simualation in the plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oFa5DYvV86Mu",
      "metadata": {
        "id": "oFa5DYvV86Mu"
      },
      "outputs": [],
      "source": [
        "with h5py.File('tng100-3/output/snapdir_098/snap_098.0.hdf5', 'r') as snapfile:\n",
        "    particle_mass = snapfile['Header'].attrs['MassTable'][1] * 1e10 #DM particles mass\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "ax.step(mass_bins[:-1], np.log10(hmf), where='post', lw=3, label='TNG100-3')\n",
        "ax.plot(bin_centers, np.log10(jenkins_mf), color='red', linestyle='--', lw = 3, label='Jenkins (2001)')\n",
        "ax.plot(bin_centers, np.log10(angulo_mf), color='green', linestyle='--', lw = 3, label='Angulo (2012)')\n",
        "ax.axvline(np.log10(particle_mass * 30), color='grey', linestyle=':', lw = 3, label='30 * DM particle mass')\n",
        "ax.axvline(np.log10(particle_mass * 200), color='k', linestyle=':', lw = 3, label='200 * DM particle mass')\n",
        "\n",
        "ax.legend()\n",
        "ax.set_xlabel('log(M_halo)')\n",
        "ax.set_ylabel('log(dN/dlogM)')\n",
        "ax.set_title('Halo Mass Function')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pTi-cqkDIvnk",
      "metadata": {
        "id": "pTi-cqkDIvnk"
      },
      "source": [
        "We can see that the simulations starts to predict _less_ haloes than expected when these haloes have less than 200 particles, and really fails miserably for haloes that have less than 20. This happens because we have reached the **resolution limit** of the simulation.\n",
        "\n",
        "At or below the resolution limit, the structures are sampled too coarsely to provide reliable results.\n",
        "* In this particular case, what happens is that the potential well of the halo cannot be resolved by few particles, so its gravitational attraction is artificially suppressed. This prevents other nearby particles from falling into the halo, and the overall mass is under-estimated.\n",
        "\n",
        "This also means that all haloes with less than 20 particles (or equivalent mass) are not well simulated, so we can not trust them. From now on, we will get rid of them!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d00f618",
      "metadata": {
        "id": "2d00f618"
      },
      "source": [
        "# Step 5: Stellar-to-halo mass relation\n",
        "\n",
        "The stellar-to-halo mass relation (SHMR) is one of the most important relations in the study of galaxy formation. It quantifies the efficiency with which galaxies convert the available material into stars.\n",
        "\n",
        "The SHMR is determined by the interaction between many different physical processes:\n",
        "* Gas cooling and accretion: how gas falls into the halo and cools to form stars.\n",
        "* Star formation efficiency: how effectively gas is converted into stars.\n",
        "* Feedback mechanisms: How much and in which form energy from stars and black holes is injected into the galaxies.\n",
        "\n",
        "This means that any model that tries to explain the Universe and the formation of galaxies, must produce a realistic SHMR.\n",
        "\n",
        "**exercise**: compute the SHMR for our simulation. Use only resolved haloes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "57f81a8e",
      "metadata": {
        "id": "57f81a8e"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6jOnBqRqPj9j",
      "metadata": {
        "id": "6jOnBqRqPj9j"
      },
      "source": [
        "## Exercise: understanding the SHMR\n",
        "\n",
        "Now, we can try to understand what is the physics that produces the SHMR in pur simulation. A simple way to do so, is to color each point by some physical quantity and see if any of these quantities explains the SHMR.\n",
        "\n",
        "Color the points in the plot with each one of the following quantities:\n",
        " - `SubhaloBHMass`\n",
        " - `SubhaloBHMdot`\n",
        " - `SubhaloGasMetallicity`\n",
        " - `SubhaloSFR`\n",
        " - sSFR = `SubhaloSFR`/M_star\n",
        " - `SubhaloSpin`\n",
        " - `SubhaloVel`\n",
        "\n",
        "\n",
        "(hint: we have never loaded this quantities, so you will have to re-load the subhaloes and ask for these quantities as well)\n",
        "\n",
        "(hint 2: some of these quantities span many orders of magnitude. If that's the case, try to use their logarithm to color the points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30eFDZGkSCfe",
      "metadata": {
        "id": "30eFDZGkSCfe"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc5bd69",
      "metadata": {
        "id": "efc5bd69"
      },
      "source": [
        "# Step 6: Merger trees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7318eca4",
      "metadata": {
        "id": "7318eca4"
      },
      "source": [
        "Merger trees are structures that provide the history of groups/subhlaoes throughout the simulation. The main information they contain is whether and when two of such structures merged, but they also store basic properties of the halo though time.\n",
        "\n",
        "In the file you downloaded, they are located in `tng100-3/postprocessing/trees/LHaloTree/`. As for the snapshot and groups, these are split in chunks. Moreover, inside each chunk there is a (large) number of HDF5 Groups called `TreeN`. These are basically just sub-chunks and we can ignore them for now.  Let's have a look at one of these tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "PuD0qeJQI6UI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuD0qeJQI6UI",
        "outputId": "c53fcce8-1ea8-4795-c0c1-b5e77ed1d49b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tree0 datasets:\n",
            "- Descendant\n",
            "- FileNr\n",
            "- FirstHaloInFOFGroup\n",
            "- FirstProgenitor\n",
            "- GroupCM\n",
            "- GroupMassType\n",
            "- Group_M_Crit200\n",
            "- Group_M_Crit500\n",
            "- Group_M_Mean200\n",
            "- Group_M_TopHat200\n",
            "- Group_R_Crit200\n",
            "- Group_R_Crit500\n",
            "- Group_R_Mean200\n",
            "- Group_R_TopHat200\n",
            "- NextHaloInFOFGroup\n",
            "- NextProgenitor\n",
            "- SnapNum\n",
            "- SubhaloBHMass\n",
            "- SubhaloBHMdot\n",
            "- SubhaloBfldDisk\n",
            "- SubhaloBfldHalo\n",
            "- SubhaloGasMetalFractions\n",
            "- SubhaloGasMetalFractionsSfr\n",
            "- SubhaloGasMetallicity\n",
            "- SubhaloGasMetallicitySfr\n",
            "- SubhaloGrNr\n",
            "- SubhaloHalfmassRad\n",
            "- SubhaloHalfmassRadType\n",
            "- SubhaloIDMostBound\n",
            "- SubhaloLen\n",
            "- SubhaloLenType\n",
            "- SubhaloMassInRadType\n",
            "- SubhaloMassType\n",
            "- SubhaloNumber\n",
            "- SubhaloOffsetType\n",
            "- SubhaloPos\n",
            "- SubhaloSFR\n",
            "- SubhaloSFRinRad\n",
            "- SubhaloSpin\n",
            "- SubhaloStarMetalFractions\n",
            "- SubhaloStarMetallicity\n",
            "- SubhaloStellarPhotometrics\n",
            "- SubhaloVMax\n",
            "- SubhaloVel\n",
            "- SubhaloVelDisp\n"
          ]
        }
      ],
      "source": [
        "with h5py.File('tng100-3/postprocessing/trees/LHaloTree/trees_sf1_099.0.hdf5', 'r') as treefile:\n",
        "    print(\"Tree0 datasets:\")\n",
        "    for key in treefile['Tree0'].keys():\n",
        "        print(f\"- {key}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uNKM4Q_ztdv0",
      "metadata": {
        "id": "uNKM4Q_ztdv0"
      },
      "source": [
        "Some of these are copies of the subhalo properties saved in the group files, but now at all available simulation times in the same file.\n",
        "\n",
        "Some other variables are new and they are used to define the connection between subhaloes progenitors/descendant (i.e. the subhalo at different snapshots). These are explained here:\n",
        "\n",
        "![lhalotree](https://raw.githubusercontent.com/manodeep/LHaloTreeReader/refs/heads/master/lhalotree-mergertree-structure.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HvMjjXL7sEXR",
      "metadata": {
        "id": "HvMjjXL7sEXR"
      },
      "source": [
        "Some important remarks:\n",
        "* `SubhaloNumber` is an identifier assigned to each subhalo. It is **unique** within any individual snapshot, but not across different snapshot. (i.e. we can not have two subhaloes with number 7 at the same snapshot, but we can have a subhalo 7 in snapshot 98 and another subhalo 7 in snapshot 99, and they are NOT related to each other.\n",
        "* `Descendant`, `FirstProgenitor` and `NextProgenitor` are **indexes** to the arrays in the merger tree. So if we have a halo at _position_ `p=0`, its first progenitor is at _position_ `FirstProgenitor[p]`, and the identifier of the progenitor is `SubhaloNumber[FirstProgenitor[p]]`.\n",
        "* To find the non-first progenitors of a halo, we neet to first find its `FirstProgenitor` and then walk to the `NextProgenitor` of it, and again, and again, ... until we run out of `NextProgenitor` (i.e. we find `NextProgenitor = -1`.\n",
        "\n",
        "The trees are usually walked backwards: we start from a halo, and load all its history at previous time in the simulation, including the histories of all the haloes that merged to form it.\n",
        "* For example, in the picture above, we can select the central halo in the bottom row and follow all its progenitors in previous snapshots: the central 3 subhalo in the penultimate row, 4 of them in the row above, etc.\n",
        "\n",
        "We can use `illustris_python` to load the past tree of a specific subhalo using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xnQoMWBMnNgr",
      "metadata": {
        "id": "xnQoMWBMnNgr"
      },
      "outputs": [],
      "source": [
        "il.lhalotree.loadTree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nJzfWs-rsWuc",
      "metadata": {
        "id": "nJzfWs-rsWuc"
      },
      "source": [
        "We can pass the `onlyMPB=True` argument to only load the **main progenitor branch**. What this mean is: whenever a halo has multiple progenitors, we only follow the _main_ progenitor, i.e. the most massive one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "Xz7tIMEAr90B",
      "metadata": {
        "id": "Xz7tIMEAr90B"
      },
      "outputs": [],
      "source": [
        "tree0 = il.lhalotree.loadTree('tng100-3/output', 98, 0, onlyMPB=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H6ldMSGvvQbr",
      "metadata": {
        "id": "H6ldMSGvvQbr"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "ax.plot(tree0['SnapNum'], np.log10(tree0['SubhaloMassType'][:,1] * 1e10)) #convert mass to Msun/h\n",
        "ax.set_xlabel('Output number')\n",
        "ax.set_ylabel(r'log( Subhalo Mass [M$_\\odot$/h] )')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58H7CKbu8DL-",
      "metadata": {
        "id": "58H7CKbu8DL-"
      },
      "source": [
        "We can now load the entire history of the subhalo by using `onlyMPB=False` and remake the plot.\n",
        "\n",
        "**Important**: when we use `illustris_python` to load the merger tree, we lose all the indexing structures, because we are loading only a small portion of the full tree structure, so indexes do not make sense anymore.\n",
        "* What `illustris_python` does, is to give us an array where each branch of the merger tree is placed one after the other.\n",
        "* There is a (complicated) rule for ordering them, but for today we just need to know that a halo history is all in a contiguous piece of the array(s) returned, and stops when it merges to the main branch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "gaOnhHDcvkeZ",
      "metadata": {
        "id": "gaOnhHDcvkeZ"
      },
      "outputs": [],
      "source": [
        "tree0 = il.lhalotree.loadTree('tng100-3/output', 98, 0, onlyMPB=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3BpK3IxD3Ail",
      "metadata": {
        "id": "3BpK3IxD3Ail"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "ax.plot(tree0['SnapNum'], np.log10(tree0['SubhaloMassType'][:,1] * 1e10)) #convert mass to Msun/h\n",
        "ax.set_xlabel('Output number')\n",
        "ax.set_ylabel(r'log( Subhalo Mass [M$_\\odot$/h] )')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GKwpaSZP8PUh",
      "metadata": {
        "id": "GKwpaSZP8PUh"
      },
      "source": [
        "**Question**: What do you see? Why is that?\n",
        "\n",
        "## identify mergers\n",
        "The next task we have is to identify mergers, i.e. when two or more subhalo merge together to form a larger structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YCC2P9Zt3rwr",
      "metadata": {
        "id": "YCC2P9Zt3rwr"
      },
      "outputs": [],
      "source": [
        "def find_mergers(tree):\n",
        "    mergers_snap = []\n",
        "    mergers_haloes = []\n",
        "    for snap in np.unique(tree['SnapNum']):\n",
        "        snap_mask = tree['SnapNum'] == snap\n",
        "        for desc in np.unique(tree['Descendant'][snap_mask]):\n",
        "            desc_mask = tree['Descendant'][snap_mask] == desc\n",
        "            if np.where(desc_mask)[0].size > 1:\n",
        "                mergers_snap.append(snap)\n",
        "                mergers_haloes.append(tree['SubhaloNumber'][snap_mask][desc_mask])\n",
        "    return mergers_snap, mergers_haloes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OTEIt11W4e0q",
      "metadata": {
        "id": "OTEIt11W4e0q"
      },
      "outputs": [],
      "source": [
        "mergers_snap, mergers_haloes = find_mergers(tree0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yQaUB7gz4j6v",
      "metadata": {
        "id": "yQaUB7gz4j6v"
      },
      "outputs": [],
      "source": [
        "for s, id in zip(mergers_snap, mergers_haloes):\n",
        "    print(f\"merger at snap {s} between subhaloes {id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "F32JkxBG8k0q",
      "metadata": {
        "id": "F32JkxBG8k0q"
      },
      "outputs": [],
      "source": [
        "treeN = il.lhalotree.loadTree('tng100-3/output', 98, 1455, onlyMPB=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "byRDAdI88q52",
      "metadata": {
        "id": "byRDAdI88q52"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "ax.plot(treeN['SnapNum'], np.log10(treeN['SubhaloMassType'][:,1] * 1e10)) #convert mass to Msun/h\n",
        "ax.set_xlabel('Output number')\n",
        "ax.set_ylabel(r'log( Subhalo Mass [M$_\\odot$/h] )')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TKGf7wzT-R0I",
      "metadata": {
        "id": "TKGf7wzT-R0I"
      },
      "outputs": [],
      "source": [
        "mergers_snap, mergers_haloes = find_mergers(treeN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zDF81kUZ_ZKE",
      "metadata": {
        "id": "zDF81kUZ_ZKE"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,1)\n",
        "\n",
        "breaks = np.where(treeN['SnapNum'][:-1] - treeN['SnapNum'][1:] < 0)[0]\n",
        "\n",
        "#isolate main branch\n",
        "main_branch = {'SnapNum': treeN['SnapNum'][:breaks[0]+1], 'SubhaloMassType':treeN['SubhaloMassType'][:breaks[0]+1,:]}\n",
        "\n",
        "#plot main branch\n",
        "ax.plot(main_branch['SnapNum'], np.log10(main_branch['SubhaloMassType'][:,1] * 1e10), 'k-', lw=4) #convert mass to Msun/h\n",
        "\n",
        "\n",
        "#plot other branches\n",
        "current_idx = breaks[0]+1\n",
        "for i,b in enumerate(breaks[1:]):\n",
        "    color = f'C{i%8}'\n",
        "    ax.plot(treeN['SnapNum'][current_idx:b+1], np.log10(treeN['SubhaloMassType'][current_idx:b+1,1] * 1e10), '-', color=color) #convert mass to Msun/h\n",
        "    #mark merger\n",
        "    mbidx = np.where(main_branch['SnapNum'] == treeN['SnapNum'][current_idx])[0][0]\n",
        "    plt.plot([main_branch['SnapNum'][mbidx], main_branch['SnapNum'][mbidx]], [np.log10(treeN['SubhaloMassType'][current_idx,1] * 1e10), np.log10(main_branch['SubhaloMassType'][mbidx,1] * 1e10)], ls='--', color=color) #dashed line\n",
        "    ax.plot(main_branch['SnapNum'][mbidx], np.log10(main_branch['SubhaloMassType'][mbidx,1] * 1e10), '*', color='yellow', mec='goldenrod', markersize=10) # star\n",
        "\n",
        "    current_idx = b+1\n",
        "\n",
        "color = f'C{i+1%8}'\n",
        "ax.plot(treeN['SnapNum'][current_idx:], np.log10(treeN['SubhaloMassType'][current_idx:,1] * 1e10), '-', color=color) #convert mass to Msun/h\n",
        "#mark merger\n",
        "mbidx = np.where(main_branch['SnapNum'] == treeN['SnapNum'][current_idx])[0][0]\n",
        "plt.plot([main_branch['SnapNum'][mbidx], main_branch['SnapNum'][mbidx]], [np.log10(treeN['SubhaloMassType'][current_idx,1] * 1e10), np.log10(main_branch['SubhaloMassType'][mbidx,1] * 1e10)], ls='--', color=color) #dashed line\n",
        "ax.plot(main_branch['SnapNum'][mbidx]                           , np.log10(main_branch['SubhaloMassType'][mbidx,1] * 1e10), '*', color='yellow', mec='goldenrod', markersize=10) # star\n",
        "\n",
        "ax.set_xlabel('Output number')\n",
        "ax.set_ylabel(r'log( Subhalo Mass [M$_\\odot$/h] )')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SCEenObejV7S",
      "metadata": {
        "id": "SCEenObejV7S"
      },
      "source": [
        "# Extra\n",
        "\n",
        "Notebook with solutions: <a href=\"https://colab.research.google.com/github/EGaraldi/EPIC_5/blob/main/Tutorials/tutorial_5/cosmo_sim_with_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VTqTxlA_kUQj",
      "metadata": {
        "id": "VTqTxlA_kUQj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
